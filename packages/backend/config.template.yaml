# AI Configuration Template
# Copy this file to config.yaml and adjust the values

ai:
  # Available providers: 'ollama' or 'openai'
  provider: ollama

  # Ollama Configuration (required if provider is 'ollama')
  ollama:
    host: http://host.docker.internal:11434
    model: llama2
    temperature: 0.7
    top_k: 40
    top_p: 0.9

  # OpenAI Configuration (required if provider is 'openai')
  openai:
    apiKey: your-api-key-here
    model: gpt-3.5-turbo
    temperature: 0.7
    maxTokens: 2000
    topP: 0.9 