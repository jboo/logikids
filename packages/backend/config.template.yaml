# AI Configuration Template
# Copy this file to config.yaml and adjust the values
server:
  port: 3000
ai:
  text:
    # Available providers: 'ollama' or 'openai'
    provider: ollama

    # Ollama Configuration (required if provider is 'ollama')
    ollama:
      host: http://host.docker.internal:11434
      model: llama2
      temperature: 0.7
      top_k: 40
      top_p: 0.9

    # OpenAI Configuration (required if provider is 'openai')
    openai:
      apiKey: your-api-key-here
      model: gpt-3.5-turbo
      temperature: 0.7
      maxTokens: 2000
      topP: 0.9

  image:
    # Available providers: 'ollama' or 'openai'
    provider: ollama

    # Ollama Configuration (required if provider is 'ollama')
    ollama:
      host: http://host.docker.internal:11434
      model: llama3.2-vision
      temperature: 0.7
      top_k: 40
      top_p: 0.9

    # OpenAI Configuration (required if provider is 'openai')
    openai:
      apiKey: your-api-key-here
      model: dall-e-3
      size: "1024x1024"
      quality: "standard"
      style: "natural" 